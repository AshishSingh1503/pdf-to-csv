# Example environment variables for this project
# Copy to .env and fill values for your environment

# Server
PORT=5000
NODE_ENV=development
LOG_LEVEL=info
WS_PATH=/ws

# Google Cloud / Document AI
GOOGLE_APPLICATION_CREDENTIALS=./server/src/config/pdf2csv-credentials.json
PROJECT_ID=pdf2csv-475708
LOCATION=us
PROCESSOR_ID=9f82bf3d2a02e2ab
OUTPUT_DIR=output
INPUT_BUCKET=pdf-data-extraction-input-bucket
OUTPUT_BUCKET=pdf-data-extraction-output-bucket

# Database
DB_HOST=localhost
DB_PORT=5432
DB_NAME=pdf2csv_db
DB_USER=postgres
DB_PASSWORD=postgres
DB_SSL=false
DB_POOL_MAX=500    # Increased for high-concurrency workloads (8 vGPU/64GB)
DB_POOL_MIN=2

# Worker and caching tuning
WORKER_THREAD_POOL_SIZE=16   # Worker threads for validation (optimized for 8 vGPU/64GB environment)
CACHE_TTL=300               # In seconds; controls in-memory cache TTL

# Bulk insert chunk size for high-performance (default: 5000)
DB_INSERT_CHUNK_SIZE=5000    # Bulk insert chunk size for high-performance (default: 5000)

# Feature toggles
ENABLE_DUPLICATE_DETECTION=true
DUPLICATE_KEY_FIELD=mobile

# High-Performance Configuration (8 vGPU / 64GB)
# These settings enable aggressive parallel processing for fast document conversion
MAX_CONCURRENT_BATCHES=10        # Process up to 20 batches simultaneously (default: 2)
BATCH_QUEUE_TIMEOUT=1800000      # 30 minutes timeout for large batches (default: 15 min)
MAX_QUEUE_LENGTH=500             # Buffer up to 500 batches (default: 100)

# Timeout for individual Document AI requests in milliseconds (default: 1200000 = 20 minutes)
# Increase for very large PDFs (>40MB). Minimum: 60000 (1 minute)
REQUEST_TIMEOUT_MS=1200000

# Optional multiplier for BATCH_QUEUE_TIMEOUT (default: 1.0, range: 0.5-5.0)
# Use to scale timeout dynamically for exceptionally large batches
# BATCH_QUEUE_TIMEOUT_MULTIPLIER=1.5
