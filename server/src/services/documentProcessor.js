// server/src/services/documentProcessor.js
import { DocumentProcessorServiceClient } from "@google-cloud/documentai";
import { config } from "../config/index.js";
import fs from "fs";
import path from "path";
import pLimit from "p-limit";


// Initialize Document AI client
let client;
try {
  const clientConfig = process.env.NODE_ENV === 'production' ? {} : { keyFilename: config.credentials };
  client = new DocumentProcessorServiceClient(clientConfig);
  console.log('‚úÖ Document AI client initialized successfully');
} catch (error) {
  console.error("üî• Failed to initialize Document AI client:", error);
  throw new Error("Failed to initialize Document AI client. Please check your Google Cloud credentials.");
}


// --- OPTIMIZATION 6: Pre-compiled Regex Patterns (Cache compiled regexes) ---
const REGEX_PATTERNS = {
  addressStatePostcodeStart: /^\s*([A-Za-z]{2,3})\s+(\d{4})\s+(.+)$/i,
  addressPostcodeStateEnd: /^\s*(\d{4})\s+(.+?)\s+([A-Za-z]{2,3})\s*$/i,
  addressStatePostcodeMiddle: /^(.+?)\s+([A-Za-z]{2,3})\s+(\d{4})\s+(.+)$/i,
  addressStatePostcodeAny: /([A-Za-z]{2,3})\s+(\d{4})/i,
  nameInvalidChars: /[^A-Za-z√Ä-√ñ√ò-√∂√∏-√ø'\-\s]/g,
  nameSpecialChars: /ÔøΩ|ÔΩ•ÔΩ•ÔΩ•|‚Ä¶|‚Ä¢|\u2026/g,
  dateInvalidChars: /[^0-9A-Za-z\s\-\/]/g,
  dateFormat: /^(\d{1,2})([A-Za-z]{3,})(\d{4})$/,
  dashNormalize: /[-\u2013\u2014]+/g,
  dashMultiple: /-{2,}/g,
  dashTrim: /^[\-\s]+|[\-\s]+$/g,
  whitespaceMultiple: /\s+/g,
  digitOnly: /\D/g,
};


// --- Helper Functions ported from Python ---

const extractEntitiesSimple = (document) => {
  return document.entities?.map(entity => ({
    type: entity.type?.toLowerCase().trim(),
    value: entity.mentionText?.trim(),
  })) || [];
};


const simpleGrouping = (entities) => {
  const records = [];
  const names = entities.filter(e => e.type === 'name').map(e => e.value);
  const mobiles = entities.filter(e => e.type === 'mobile').map(e => e.value);
  const addresses = entities.filter(e => e.type === 'address').map(e => e.value);
  const emails = entities.filter(e => e.type === 'email').map(e => e.value);
  const dobs = entities.filter(e => e.type === 'dateofbirth').map(e => e.value);
  const landlines = entities.filter(e => e.type === 'landline').map(e => e.value);
  const lastseens = entities.filter(e => e.type === 'lastseen').map(e => e.value);

  const maxCount = Math.max(names.length, mobiles.length, addresses.length, emails.length, dobs.length, landlines.length, lastseens.length);

  for (let i = 0; i < maxCount; i++) {
    const record = {};
    if (i < names.length) {
      const nameParts = names[i].split(' ');
      record.first_name = nameParts[0] || '';
      record.last_name = nameParts.slice(1).join(' ') || '';
    }
    if (i < mobiles.length) record.mobile = mobiles[i];
    if (i < addresses.length) record.address = addresses[i];
    if (i < emails.length) record.email = emails[i];
    if (i < dobs.length) record.dateofbirth = dobs[i];
    if (i < landlines.length) record.landline = landlines[i];
    if (i < lastseens.length) record.lastseen = lastseens[i];

    if (record.first_name) {
      records.push(record);
    }
  }
  return records;
};


const _single_line_address = (address) => {
  if (!address) return '';
  let s = address.replace(/\r/g, ' ').replace(/\n/g, ' ');
  s = s.replace(/[,;\|/]+/g, ' ');
  s = s.replace(REGEX_PATTERNS.whitespaceMultiple, ' ').trim();
  s = s.endsWith('.') ? s.slice(0, -1) : s;
  return s;
}


const fixAddressOrdering = (address) => {
  if (!address) return address;

  let s = _single_line_address(address).trim();
  let match;

  // Pattern A: State + Postcode at the beginning
  match = s.match(REGEX_PATTERNS.addressStatePostcodeStart);
  if (match) {
    const [, state, postcode, rest] = match;
    const out = `${rest.trim()} ${state.toUpperCase()} ${postcode}`;
    return out.replace(REGEX_PATTERNS.whitespaceMultiple, ' ').trim();
  }

  // Pattern B: Postcode at beginning and state at end
  match = s.match(REGEX_PATTERNS.addressPostcodeStateEnd);
  if (match) {
    const [, postcode, rest, state] = match;
    const out = `${rest.trim()} ${state.toUpperCase()} ${postcode}`;
    return out.replace(REGEX_PATTERNS.whitespaceMultiple, ' ').trim();
  }

  // Pattern C: State + Postcode in the middle
  match = s.match(REGEX_PATTERNS.addressStatePostcodeMiddle);
  if (match) {
    const [, part1, state, postcode, part2] = match;
    const out = `${part1.trim()} ${part2.trim()} ${state.toUpperCase()} ${postcode}`;
    return out.replace(REGEX_PATTERNS.whitespaceMultiple, ' ').trim();
  }

  // Pattern D: If any state+postcode pair exists anywhere, move it to the end
  match = s.match(REGEX_PATTERNS.addressStatePostcodeAny);
  if (match) {
    const state = match[1].toUpperCase();
    const postcode = match[2];
    const rest = (s.substring(0, match.index) + s.substring(match.index + match[0].length)).trim();
    const out = `${rest.replace(REGEX_PATTERNS.whitespaceMultiple, ' ')} ${state} ${postcode}`;
    return out.trim();
  }

  return s;
};


const cleanName = (name) => {
  if (!name) return '';
  let s = name.trim();
  s = s.replace(REGEX_PATTERNS.nameSpecialChars, '');
  s = s.replace(/[\d?]+/g, '');
  s = s.replace(REGEX_PATTERNS.nameInvalidChars, '');
  s = s.replace(REGEX_PATTERNS.whitespaceMultiple, ' ').trim();
  const parts = s ? s.split(' ').map(p => p.charAt(0).toUpperCase() + p.slice(1)) : [];
  return parts.join(' ').trim();
};


const normalizeDateField = (dateStr) => {
  if (!dateStr) return '';
  let s = dateStr.trim();
  s = s.replace(REGEX_PATTERNS.dashNormalize, '-');
  s = s.replace(REGEX_PATTERNS.dashMultiple, '-');
  s = s.replace(REGEX_PATTERNS.dashTrim, '');
  s = s.replace(REGEX_PATTERNS.dateInvalidChars, '');
  s = s.replace(/\./g, '-');

  const match = s.match(REGEX_PATTERNS.dateFormat);
  if (match) {
    s = `${match[1]}-${match[2]}-${match[3]}`;
  }

  try {
    const dt = new Date(s);
    if (isNaN(dt.getTime())) return '';
    const year = dt.getFullYear();
    const month = String(dt.getMonth() + 1).padStart(2, '0');
    const day = String(dt.getDate()).padStart(2, '0');
    return `${year}-${month}-${day}`;
  } catch (e) {
    return '';
  }
};

// NEW: Validate landline - must be >= 10 digits
const isValidLandline = (landline) => {
  if (!landline) return false;
  const digits = landline.replace(REGEX_PATTERNS.digitOnly, '');
  return digits.length >= 10;
};

const cleanAndValidate = (records) => {
  const cleanRecords = [];

  for (const record of records) {
    const rawFirst = record.first_name?.trim() || '';
    const rawLast = record.last_name?.trim() || '';
    const rawDob = record.dateofbirth?.trim() || '';
    const rawLastseen = record.lastseen?.trim() || '';

    const firstName = cleanName(rawFirst);
    const lastName = cleanName(rawLast);

    const mobile = record.mobile?.trim() || '';
    let address = record.address?.trim() || '';
    const email = record.email?.trim() || '';
    const rawLandline = record.landline?.trim() || '';

    address = fixAddressOrdering(address);

    const dateofbirth = normalizeDateField(rawDob);
    const lastseen = normalizeDateField(rawLastseen);

    if (!firstName || firstName.length <= 1) continue;
    if (!mobile) continue;

    const mobileDigits = mobile.replace(REGEX_PATTERNS.digitOnly, '');
    if (!(mobileDigits.length === 10 && mobileDigits.startsWith('04'))) continue;

    if (!address || !/\d/.test(address.substring(0, 25))) continue;

    // Only include landline if it has >= 10 digits
    const landline = isValidLandline(rawLandline) ? rawLandline.replace(REGEX_PATTERNS.digitOnly, '') : '';

    cleanRecords.push({
      first_name: firstName,
      last_name: lastName,
      dateofbirth: dateofbirth || '',
      address: address,
      mobile: mobileDigits,
      email: email || '',
      landline: landline,
      lastseen: lastseen || '',
    });
  }

  const uniqueRecords = [];
  const seenMobiles = new Set();
  for (const record of cleanRecords) {
    if (!seenMobiles.has(record.mobile)) {
      uniqueRecords.push(record);
      seenMobiles.add(record.mobile);
    }
  }

  return uniqueRecords;
};

// --- OPTIMIZATION 5 & 7: Memory-Efficient Buffering & Concurrent File Reading ---
/**
 * Read multiple files concurrently with Promise.all
 * OPTIMIZATION 7: Parallel async file reads instead of sequential
 */
const readFilesBuffered = async (pdfFiles) => {
  const fileBuffers = await Promise.all(
    pdfFiles.map(file =>
      new Promise((resolve, reject) => {
        const tempPath = path.join(process.cwd(), "temp", file.name);
        fs.readFile(tempPath, (err, data) => {
          if (err) reject(err);
          else resolve({ fileName: file.name, buffer: data, tempPath });
        });
      })
    )
  );
  return fileBuffers;
};

// --- OPTIMIZATION 2: Batch Database Inserts ---
/**
 * Batch insert records into database
 * Expects database connection/client to be available
 * This is a template - adjust based on your database (PostgreSQL, MongoDB, etc.)
 */
export const batchInsertRecords = async (records, dbClient, batchSize = 500) => {
  if (!records || records.length === 0) {
    console.log('‚ö†Ô∏è  No records to insert');
    return { insertedCount: 0, batches: 0 };
  }

  let insertedCount = 0;
  let batchCount = 0;

  try {
    // Process records in batches
    for (let i = 0; i < records.length; i += batchSize) {
      const batch = records.slice(i, i + batchSize);
      batchCount++;

      // Example for PostgreSQL with pg-promise or similar
      // Adjust this based on your actual database setup
      if (dbClient && typeof dbClient.insertBatch === 'function') {
        const result = await dbClient.insertBatch(batch);
        insertedCount += result.rowCount || batch.length;
      } else if (dbClient && typeof dbClient.collection === 'function') {
        // MongoDB example
        const result = await dbClient.collection('records').insertMany(batch);
        insertedCount += result.insertedCount;
      }

      console.log(`üì¶ Batch ${batchCount}: Inserted ${batch.length} records`);
    }

    console.log(`‚úÖ Total inserted: ${insertedCount} records in ${batchCount} batches`);
    return { insertedCount, batches: batchCount };
  } catch (error) {
    console.error('‚ùå Error in batch insert:', error.message);
    throw error;
  }
};

// --- OPTIMIZATION 4: Exponential Backoff for Rate Limiting ---
/**
 * Retry function with exponential backoff for handling API rate limits
 */
const retryWithBackoff = async (fn, maxRetries = 3, initialDelay = 1000) => {
  let lastError;

  for (let attempt = 0; attempt < maxRetries; attempt++) {
    try {
      return await fn();
    } catch (error) {
      lastError = error;
      const isRateLimit = error.code === 429 || error.message?.includes('RESOURCE_EXHAUSTED');

      if (isRateLimit && attempt < maxRetries - 1) {
        const delay = initialDelay * Math.pow(2, attempt);
        console.warn(`‚è±Ô∏è  Rate limited. Retrying after ${delay}ms (attempt ${attempt + 1}/${maxRetries})`);
        await new Promise(resolve => setTimeout(resolve, delay));
      } else if (!isRateLimit) {
        throw error;
      }
    }
  }

  throw lastError;
};

// --- Main Processing Function (Backward Compatible) ---

/**
 * Process PDFs with optimizations for 1-200+ files
 * BACKWARD COMPATIBLE: Works with existing code without breaking changes
 * 
 * @param {Array} pdfFiles - Array of PDF file objects
 * @param {Number} batchSize - Records per batch for DB inserts (default: 500)
 * @param {Number} maxWorkers - Max concurrent workers (auto-scaled based on file count)
 * @returns {Promise<Object>} Same format as original function
 */
export const processPDFs = async (pdfFiles, batchSize = 10, maxWorkers = 4) => {
  // OPTIMIZATION: Auto-scale workers based on file count
  // For 1 file: use 2 workers
  // For 10 files: use 5 workers
  // For 100+ files: use 20 workers
  let scaledWorkers = maxWorkers;
  if (pdfFiles.length === 1) {
    scaledWorkers = 2;
  } else if (pdfFiles.length <= 10) {
    scaledWorkers = Math.min(5, pdfFiles.length);
  } else if (pdfFiles.length > 50) {
    scaledWorkers = 20;
  } else if (pdfFiles.length > 10) {
    scaledWorkers = Math.max(maxWorkers, Math.ceil(pdfFiles.length / 10));
  }

  console.log(`üìä Processing ${pdfFiles.length} files | Workers: ${scaledWorkers}`);
  const limit = pLimit(scaledWorkers);
  const startTime = Date.now();

  try {
    const tempDir = path.join(process.cwd(), "temp");
    if (!fs.existsSync(tempDir)) fs.mkdirSync(tempDir, { recursive: true });

    const processFile = async (file, index) => {
      const tempPath = path.join(tempDir, file.name);

      try {
        // Save uploaded file to temp
        await file.mv(tempPath);

        // OPTIMIZATION 4: Use retry with backoff for API calls
        const [result] = await retryWithBackoff(async () => {
          return await client.processDocument({
            name: `projects/${config.projectId}/locations/${config.location}/processors/${config.processorId}`,
            rawDocument: {
              content: fs.readFileSync(tempPath),
              mimeType: "application/pdf",
            },
          });
        }, 3, 1000);

        const entities = extractEntitiesSimple(result.document);
        const rawRecords = simpleGrouping(entities);
        const filteredRecords = cleanAndValidate(rawRecords);

        rawRecords.forEach(r => r.file_name = file.name);
        filteredRecords.forEach(r => r.file_name = file.name);

        const preProcessingRecords = rawRecords.map(record => ({
          full_name: `${record.first_name || ''} ${record.last_name || ''}`.trim(),
          dateofbirth: record.dateofbirth,
          address: record.address,
          mobile: record.mobile,
          email: record.email,
          landline: record.landline,
          lastseen: record.lastseen,
          file_name: record.file_name
        }));

        const preProcessingJson = {
          file_name: file.name,
          processing_timestamp: new Date().toISOString(),
          raw_records: preProcessingRecords,
          document_ai_entities: entities,
          total_entities: entities.length,
          entity_types: [...new Set(entities.map(e => e.type))],
          raw_text: result.document.text,
          metadata: {
            processor_id: config.processorId,
            project_id: config.projectId,
            location: config.location
          }
        };

        const postProcessingJson = {
          file_name: file.name,
          processing_timestamp: new Date().toISOString(),
          raw_records: rawRecords,
          filtered_records: filteredRecords,
          summary: {
            total_raw_records: rawRecords.length,
            total_filtered_records: filteredRecords.length,
            success_rate: rawRecords.length > 0 ? `${((filteredRecords.length / rawRecords.length) * 100).toFixed(1)}%` : "0%"
          },
          field_counts: {
            names: rawRecords.filter(r => r.first_name).length,
            dateofbirths: rawRecords.filter(r => r.dateofbirth).length,
            addresses: rawRecords.filter(r => r.address).length,
            mobiles: rawRecords.filter(r => r.mobile).length,
            emails: rawRecords.filter(r => r.email).length,
            landlines: rawRecords.filter(r => r.landline).length,
            lastseens: rawRecords.filter(r => r.lastseen).length
          },
          metadata: {
            processor_id: config.processorId,
            project_id: config.projectId,
            location: config.location
          }
        };

        console.log(`‚úÖ [${index + 1}/${pdfFiles.length}] ${file.name} ‚Üí ${filteredRecords.length} records`);

        return {
          rawRecords,
          filteredRecords,
          preProcessingJson,
          postProcessingJson,
        };
      } catch (fileError) {
        console.error(`‚ùå [${index + 1}/${pdfFiles.length}] ${file.name} error:`, fileError.message);
        return {
          rawRecords: [],
          filteredRecords: [],
          preProcessingJson: null,
          postProcessingJson: null,
          error: fileError.message
        };
      } finally {
        // Cleanup temp file
        if (fs.existsSync(tempPath)) {
          try {
            fs.unlinkSync(tempPath);
          } catch (unlinkError) {
            console.warn(`‚ö†Ô∏è  Failed to delete temp file ${tempPath}`);
          }
        }
      }
    };

    // Process files with concurrency limit
    const processingPromises = pdfFiles.map((file, index) =>
      limit(() => processFile(file, index))
    );

    // OPTIMIZATION 5: Buffer results in chunks instead of loading all at once
    const results = await Promise.all(processingPromises);

    // Aggregate results
    const allRawRecords = results
      .filter(r => !r.error)
      .flatMap(r => r.rawRecords);
    
    const allFilteredRecords = results
      .filter(r => !r.error)
      .flatMap(r => r.filteredRecords);
    
    const allPreProcessingJson = results
      .filter(r => r.preProcessingJson)
      .map(r => r.preProcessingJson);
    
    const allPostProcessingJson = results
      .filter(r => r.postProcessingJson)
      .map(r => r.postProcessingJson);

    const processingTime = ((Date.now() - startTime) / 1000).toFixed(2);
    const successRate = allRawRecords.length > 0 
      ? `${((allFilteredRecords.length / allRawRecords.length) * 100).toFixed(1)}%` 
      : "0%";

    console.log(`\n‚è±Ô∏è  Processing complete in ${processingTime}s | Success rate: ${successRate}`);

    return {
      allRawRecords,
      allFilteredRecords,
      allPreProcessingJson,
      allPostProcessingJson,
    };
  } catch (error) {
    console.error("Error in processPDFs:", error);
    throw error;
  }
};